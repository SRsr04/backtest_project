# detect_h1_fvg.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import random
from math import ceil
from datetime import datetime, timedelta
from time import sleep

import pytz  # –∑–∞–ª–∏—à–∞—î–º–æ pytz
import pandas as pd
import numpy as np
from okx.MarketData import MarketAPI

# --- Global Timezone Definition ---
try:
    from zoneinfo import ZoneInfo
    kyiv_tz = ZoneInfo('Europe/Kyiv')
except ImportError:
    kyiv_tz = pytz.timezone('Europe/Kyiv')

# --- Configuration ---
INST_ID = "BTC-USDT-SWAP"
TF = '15m'                 # 1-–≥–æ–¥–∏–Ω–Ω—ñ —Å–≤—ñ—á–∫–∏ –¥–ª—è FVG
LIMIT = 300               # –º–∞–∫—Å–∏–º—É–º —É OKX
DAYS_TO_FETCH = 1826      # —Ä—ñ–≤–Ω–æ 5 –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–∏—Ö —Ä–æ–∫—ñ–≤ (—ñ–∑ 2024)

# Output file names reflecting H1 timeframe
CANDLES_OUTPUT_FILE = "m15_fvg_candels.csv"             # –∑–∞–ª–∏—à–∞—é —è–∫ —É —Ç–≤–æ—î–º—É –∫–æ–¥—ñ
FVG_OUTPUT_FILE     = "btc/fvg_m15.csv"

# –†–µ–π—Ç-–ª—ñ–º—ñ—Ç/—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å
SAFE_SLEEP_EVERY = 50     # –∫–æ—Ä–æ—Ç–∫–∞ –ø–∞—É–∑–∞ –∫–æ–∂–Ω—ñ N –∑–∞–ø–∏—Ç—ñ–≤
SAFE_SLEEP_SEC   = 2
REFRESH_CLIENT_EVERY = 1000
RETRY_MAX  = 6
RETRY_BASE = 2
RETRY_CAP  = 30

# --- Helper Function ---
def ensure_dir(path: str):
    d = os.path.dirname(path)
    if d:
        os.makedirs(d, exist_ok=True)

def from_str_ms(ms_str: str) -> datetime:
    """–ö–æ–Ω–≤–µ—Ä—Ç—É—î —Ä—è–¥–æ–∫ –º—ñ—Ç–∫–∏ —á–∞—Å—É –≤ –º—Å ‚Üí datetime –∑–∞ UTC."""
    return datetime.fromtimestamp(int(ms_str) / 1000, tz=pytz.UTC)

# --- Candlestick Download Logic (FAST) ---
def fetch_candles_from_okx(inst_id: str, tf: str, limit: int, days_to_fetch: int) -> pd.DataFrame:
    """
    –®–≤–∏–¥–∫–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö —Å–≤—ñ—á–æ–∫ –∑ OKX —ñ–∑ —Ä–µ—Ç—Ä—ñ, –∫—É—Ä—Å–æ—Ä–æ–º —ñ –ø–∞—É–∑–∞–º–∏.
    –ü–æ–≤–µ—Ä—Ç–∞—î DataFrame –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏: timestamp, datetime_utc, open, high, low, close, volume.
    """
    print(f"*** OKX {tf} Candles ‚Äì Last {days_to_fetch // 365} Years for {inst_id} ***")

    # –º–µ–∂–∞ —É —á–∞—Å—ñ: –π–¥–µ–º–æ —É –º–∏–Ω—É–ª–µ, –ø–æ–∫–∏ –Ω–µ –ø–µ—Ä–µ–π–¥–µ–º–æ —Ü—é –¥–∞—Ç—É
    min_dt = datetime.now(tz=pytz.UTC) - timedelta(days=days_to_fetch)

    # –±–∞—Ä—ñ–≤ –Ω–∞ –¥–æ–±—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ TF (–¥–ª—è –≤–µ—Ä—Ö–Ω—å–æ—ó –º–µ–∂—ñ —Å—Ç–æ—Ä—ñ–Ω–æ–∫)
    bars_per_day = {
        '1s': 86400, '1m': 1440, '3m': 480, '5m': 288, '15m': 96, '30m': 48,
        '1H': 24, '2H': 12, '4H': 6, '6H': 4, '12H': 2, '1D': 1
    }.get(tf, 24)

    pages_needed = ceil(days_to_fetch * bars_per_day / limit) + 50  # –Ω–µ–≤–µ–ª–∏–∫–∏–π –±—É—Ñ–µ—Ä

    def fetch_with_retry(cl, **kwargs):
        for attempt in range(1, RETRY_MAX + 1):
            try:
                r = cl.get_history_candlesticks(**kwargs)
                return r.get("data", [])
            except Exception as e:
                delay = min(RETRY_BASE * (2 ** (attempt - 1)), RETRY_CAP)
                delay += random.uniform(0, 0.5 * delay)  # –¥–∂–∏—Ç—Ç–µ—Ä
                print(f"[WARN] {e}. retry {attempt}/{RETRY_MAX} in {delay:.1f}s...")
                sleep(delay)
                # –ù–∞ –ø–∞—Ä–Ω–∏—Ö —Å–ø—Ä–æ–±–∞—Ö ‚Äî –ø–µ—Ä–µ—Å–æ–∑–¥–∞—î–º–æ –∫–ª—ñ—î–Ω—Ç
                if attempt % 2 == 0:
                    try:
                        cl = MarketAPI(flag="0", debug=False)
                        print("[INFO] –ö–ª—ñ—î–Ω—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–æ.")
                    except Exception as e2:
                        print(f"[WARN] –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç–∏ –∫–ª—ñ—î–Ω—Ç: {e2}")
        raise RuntimeError("–í–∏—á–µ—Ä–ø–∞–Ω–æ —Ä–µ—Ç—Ä—ñ –¥–ª—è get_history_candlesticks")

    records = []
    seen_ts = set()
    cursor = None  # —Ä—É—Ö —É –º–∏–Ω—É–ª–µ —á–µ—Ä–µ–∑ after=min_ts –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó –ø–∞—á–∫–∏

    cl = MarketAPI(flag="0", debug=False)

    for page in range(1, pages_needed + 1):
        if page % REFRESH_CLIENT_EVERY == 0:
            try:
                cl = MarketAPI(flag="0", debug=False)
                print(f"[INFO] REFRESH_CLIENT_EVERY: –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–æ –∫–ª—ñ—î–Ω—Ç –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ {page}.")
            except Exception as e:
                print(f"[WARN] –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç–∏ –∫–ª—ñ—î–Ω—Ç: {e}")

        kwargs = dict(instId=inst_id, bar=tf, limit=limit)
        if cursor is not None:
            kwargs["after"] = str(cursor)  # –¥–∞—î —Å—Ç–∞—Ä—ñ—à—ñ —Å–≤—ñ—á–∫–∏

        data = fetch_with_retry(cl, **kwargs)
        if not data:
            print("No more data received. Stopping.")
            break

        min_ts_in_batch = None
        hit_time_boundary = False

        for c in data:
            ts = int(c[0])
            dt = from_str_ms(c[0])

            if min_ts_in_batch is None or ts < min_ts_in_batch:
                min_ts_in_batch = ts

            if dt < min_dt:
                hit_time_boundary = True
                continue

            if ts in seen_ts:
                continue
            seen_ts.add(ts)

            records.append({
                'timestamp': ts,          # –º—Å
                'datetime_utc': dt,
                'open':  float(c[1]),
                'high':  float(c[2]),
                'low':   float(c[3]),
                'close': float(c[4]),
                'volume': float(c[7]),
            })

        if min_ts_in_batch is None or (cursor is not None and min_ts_in_batch >= cursor):
            print("–ü–∞–≥—ñ–Ω–∞—Ü—ñ—è –Ω–µ —Ä—É—Ö–∞—î—Ç—å—Å—è –≤ –º–∏–Ω—É–ª–µ. –ó—É–ø–∏–Ω–∫–∞.")
            break
        cursor = min_ts_in_batch

        if hit_time_boundary:
            print(f"–î–æ—Å—è–≥–Ω—É—Ç–æ –º–µ–∂—ñ {min_dt.date()}. –ó—É–ø–∏–Ω–∫–∞.")
            break

        if len(data) < limit:
            print(f"Finished fetching data. Received {len(data)} (< {limit}) —É –æ—Å—Ç–∞–Ω–Ω—ñ–π –ø–∞—á—Ü—ñ.")
            break

        if page % SAFE_SLEEP_EVERY == 0:
            print(f"Page {page} processed, short pause...")
            sleep(SAFE_SLEEP_SEC)

    if not records:
        print("Fetched 0 candles.")
        return pd.DataFrame()

    df = pd.DataFrame(records)
    print(f"\nFetched {len(df)} candles.")
    return df

# --- FVG Detection Logic (—è–∫ —É —Ç–µ–±–µ) ---
def detect_fvg(df_candles_slice: pd.DataFrame) -> dict | None:
    if len(df_candles_slice) < 3:
        return None

    c0 = df_candles_slice.iloc[0]
    c1 = df_candles_slice.iloc[1]
    c2 = df_candles_slice.iloc[2]

    bullish = (c2['low']  > c0['high'])
    bearish = (c2['high'] < c0['low'])

    if bullish:
        return {
            'type': 'bullish',
            'min': c0['high'],
            'max': c2['low'],
            'time': c2['timestamp']
        }
    if bearish:
        return {
            'type': 'bearish',
            'min': c2['high'],
            'max': c0['low'],
            'time': c2['timestamp']
        }
    return None

def detect_fvgs_from_dataframe(df: pd.DataFrame) -> list[dict]:
    df = df.sort_values(by='timestamp', ascending=True)
    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
    df = df.set_index('datetime')

    detected = []
    for i in range(len(df) - 2):
        sl = df.iloc[i:i+3]
        fvg = detect_fvg(sl)
        if fvg:
            detected.append({
                'time':   pd.to_datetime(fvg['time'], unit='ms', utc=True),
                'type':   fvg['type'],
                'min':    float(fvg['min']),
                'max':    float(fvg['max']),
                'middle': (float(fvg['min']) + float(fvg['max'])) / 2.0,
            })
    return detected

# --- Main execution flow ---
def main_fvg_script():
    print(f"Running FVG detection script for {INST_ID} on {TF} over {DAYS_TO_FETCH // 365} years.")

    # 1) Fetch H1 candles fast
    df_candles = fetch_candles_from_okx(INST_ID, TF, LIMIT, DAYS_TO_FETCH)
    if df_candles.empty:
        print("No candlestick data to process. Exiting.")
        return

    # –î–µ–¥—É–ø + –≤–ø–æ—Ä—è–¥–∫—É–≤–∞–Ω–Ω—è, –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å–∏—Ä–∏—Ö —Å–≤—ñ—á–æ–∫ (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏)
    df_candles = df_candles.drop_duplicates(subset=['timestamp']).sort_values('timestamp')
    # (–æ–ø—Ü.) –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å–∏—Ä–∏—Ö —Å–≤—ñ—á–æ–∫:
    # ensure_dir(CANDLES_OUTPUT_FILE)
    # df_candles.to_csv(CANDLES_OUTPUT_FILE, index=False)
    # print(f"\nSaved {len(df_candles)} H1 candles to: {CANDLES_OUTPUT_FILE}")

    # 2) Detect FVGs
    print("\nDetecting FVGs...")
    fvgs_list = detect_fvgs_from_dataframe(df_candles)
    print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(fvgs_list)} FVG")

    if not fvgs_list:
        print("No FVGs detected.")
        return

    df_fvgs = pd.DataFrame(fvgs_list)
    df_fvgs['time'] = df_fvgs['time'].dt.tz_convert(kyiv_tz)

    # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: –≤—ñ–¥ –Ω–æ–≤–∏—Ö –¥–æ —Å—Ç–∞—Ä–∏—Ö
    df_fvgs = df_fvgs.drop_duplicates(keep='first', subset=['time','type','min','max'])
    df_fvgs = df_fvgs.sort_values(by='time', ascending=False)

    ensure_dir(FVG_OUTPUT_FILE)
    df_fvgs.to_csv(FVG_OUTPUT_FILE, index=False)
    print(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(df_fvgs)} FVG —É —Ñ–∞–π–ª {FVG_OUTPUT_FILE}")

if __name__ == "__main__":
    main_fvg_script()
